{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sairushitha/class-files/blob/main/Assignment_1nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wknRrNHwjodK"
      },
      "source": [
        "#**ASSIGNMENT 1**\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "---\n",
        "* Please download the provided IPython Notebook (ipynb) file and open it in Google Colab. Once opened, enter your code in the same file directly beneath the relevant question's code block.\n",
        "* Insert a text block below your code to briefly explain it, mentioning any libraries or functions utilized. Answer the questions in brief with examples.\n",
        "\n",
        "* Submit  \n",
        "1. The IPython Notebook (ipynb) file.  \n",
        "2. A PDF version of the notebook (converted from ipynb).\n",
        "3. The similarity score should be less than 15%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0MGUnuLnXue"
      },
      "source": [
        "#**Task 1: Tokenization & & Sentence Segmentation(20%)**\n",
        "(refer to the spacy tokenization concept which is explained after Question1 in activity-1)\n",
        "\n",
        "**Question -1:**\n",
        "\n",
        "##How can incorporating contextual information beyond single words enhance tokenization and improve performance in downstream tasks such as machine translation or question answering?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9jooJ_D1UQp"
      },
      "source": [
        "Answer Here:Employing context outside of individual words gives strength to tokenization by allowing models to identify words within their context, providing improved performance for tasks like machine translation and question answering. Tokenization without context will incorrectly split multi-word units like \"New York\" or misinterpret such words as \"bank,\" either a bank as in an institution or the riverbank. By being context-aware, tokenization prevents words from being misclassified and wrongly interpreted on the basis of meaning. This is important with languages that have heavily convoluted word construction, such that dismantling words incorrectly would transform their entire meaning. When it comes to machine translation, context helps maintain the correct structure and meaning of sentences across languages. Context interpretation in question-answering systems allows the model to accurately select relevant information. Context-aware tokenization also improves sentence segmentation by distinguishing between abbreviations and actual sentence breaks. Overall, by maintaining word relationships, contextual tokenization improves the accuracy and performance of NLP models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIl7PgRaeGjn"
      },
      "source": [
        "#####**Question 2**\n",
        "##Develop a tokenizer that considers contractions like \"can't\" and \"doesn't\", splitting them into their constituent words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aQ_rfINQfbA2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "28034cf7-1632-4cf9-b5be-3e2e1799a047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'would', 'not', 'have', 'guessed', 'that', 'she', 'would', 'leave', 'early,', 'but', 'it', 'does', 'not', 'seem', 'surprising', 'now.', \"They're\", 'not', 'coming', 'either,', 'are', 'they?']\n"
          ]
        }
      ],
      "source": [
        "text=\"I wouldn't've guessed that she'd leave early, but it doesn't seem surprising now. They're not coming either, are they?.\"\n",
        "#CODE HERE\n",
        "import re\n",
        "\n",
        "def expand_words(sentence):\n",
        "    word_exp = {\n",
        "        \"can't\": \"can not\", \"doesn't\": \"does not\", \"wouldn't've\": \"would not have\",\n",
        "        \"she'd\": \"she would\", \"they're\": \"they are\", \"isn't\": \"is not\", \"aren't\": \"are not\",\n",
        "        \"I'm\": \"I am\", \"it's\": \"it is\", \"he's\": \"he is\", \"she's\": \"she is\",\n",
        "        \"didn't\": \"did not\", \"haven't\": \"have not\", \"hasn't\": \"has not\"\n",
        "    }\n",
        "\n",
        "    for short_form, full_form in word_exp.items():\n",
        "        sentence = re.sub(r'\\b' + re.escape(short_form) + r'\\b', full_form, sentence)\n",
        "\n",
        "    return sentence.split()\n",
        "input_txt = \"I wouldn't've guessed that she'd leave early, but it doesn't seem surprising now. They're not coming either, are they?\"\n",
        "result = expand_words(input_txt)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPFkNDdLLDW-"
      },
      "source": [
        "###This Python script consolidates contractions within sentence first, after that word division of sentence is done. The function expand_shortened_words() makes use of wordbook that translates shortened wordings into full wordings by using re.sub() to make word division possible accurately. With input sentence \"I wouldn't've guessed that she'd leave early, but it doesn't seem surprising now.\", it converts \"wouldn't've\" into \"would not have\" and \"she'd\" into \"she would\" to give well-cleared word lists that can undergo subsequent processes.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BRekASOnmsz"
      },
      "source": [
        "\n",
        "**Question 3:**\n",
        "##Implement a Python script to remove Twitter username handles from a given twitter text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MD-tQZKsCkL",
        "outputId": "e143c305-e85f-49d0-a15d-64defd666e39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Awesome brainstorming session with  and ! Excited for what‚Äôs next. Appreciate the valuable input  üí°üöÄ #collaboration #growth\n"
          ]
        }
      ],
      "source": [
        "text=\"Awesome brainstorming session with @AlexM and @SamanthaT! Excited for what‚Äôs next. Appreciate the valuable input @DevMaster üí°üöÄ #collaboration #growth\"\n",
        "#CODE HERE\n",
        "import re\n",
        "def filter(msg):\n",
        "    processed_msg = re.sub(r'@\\w+', '', msg).strip()\n",
        "    return processed_msg\n",
        "tweet_txt = \"Awesome brainstorming session with @AlexM and @SamanthaT! Excited for what‚Äôs next. Appreciate the valuable input @DevMaster üí°üöÄ #collaboration #growth\"\n",
        "filtered_txt = filter(tweet_txt)\n",
        "print(filtered_txt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH_gxda3LDW_"
      },
      "source": [
        "###This script is using re.sub() to remove usernames' Twitter handles (@AlexM, @SamanthaT, @DevMaster) within a tweet. It is using @ followed by alphabets or numerals (@\\w+) to replace anything that is preceded by @, by nothing. The .strip() is ensuring that no spaces are added after that. The tweet after cleaning is printed, keeping everything else including hashtags and emojis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyRZ4X3Aucy1"
      },
      "source": [
        "**Question 4:**\n",
        "\n",
        "##In many NLP tasks, especially tasks involving large documents, it's important to not just tokenize words but also segment sentences. Write a Python script to segment a multi-paragraph text into individual sentences, considering the following cases:\n",
        "\n",
        "Sentences ending with abbreviations like \"Dr.\", \"Mr.\", etc.\n",
        "Sentences that contain dialogue within quotation marks.\n",
        "Use spaCy or NLTK for sentence segmentation and briefly explain how contextual awareness impacts this process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mvGnXMtpx0mT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "264d1a85-2f5a-4519-b45a-9d764f809b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fv3DDOgFuhbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "8c5af26d-7c77-43c7-e420-a4c7399b3995"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 1) (<ipython-input-2-f60b7a796994>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-f60b7a796994>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Input_example_text ='Dr. Adams, a renowned scientist, stated, \"We\\'ll analyze the samples by 3 p.m. tomorrow.\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
          ]
        }
      ],
      "source": [
        "Input_example_text ='Dr. Adams, a renowned scientist, stated, \"We\\'ll analyze the samples by 3 p.m. tomorrow."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "def segment_sentences(text):\n",
        "    # Load English NLP model\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    # Process the text\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Extract sentences\n",
        "    sentences = [sent.text for sent in doc.sents]\n",
        "\n",
        "    return sentences\n",
        "\n",
        "# Example multi-paragraph text\n",
        "text = \"\"\"Dr. Smith said, \"The experiment was a success.\" However, Mr. Johnson disagreed.\n",
        "He argued, \"The results are inconclusive.\" Meanwhile, the research continued.\"\"\"\n",
        "\n",
        "# Segment sentences\n",
        "result = segment_sentences(text)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fvNYhxGTOXJT",
        "outputId": "86c9231d-2dac-4b3f-c2e7-0c56eb969add"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dr. Smith said, \"The experiment was a success.\"', 'However, Mr. Johnson disagreed. \\n', 'He argued, \"The results are inconclusive.\"', 'Meanwhile, the research continued.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zME8pbf7KWZG"
      },
      "source": [
        "#**Task 2.  - Regular Expressions (30%)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPmnJt4iLDXA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk8BMMwILDXA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqFJ2tR-LDXA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRR6kMx1haKo"
      },
      "source": [
        "###**Regular Expressions**\n",
        "A regular expression, often abbreviated as regex, is a powerful and flexible tool for pattern matching and text manipulation. It consists of a sequence of characters that defines a search pattern, allowing you to perform various text-related tasks such as text validation, data extraction, text cleaning, and more. Regular expressions are used in programming languages and text editors and are constructed using a combination of regular characters, special characters, and metacharacters to specify search criteria. Learning to use regular expressions effectively can greatly enhance text processing tasks, making them a valuable skill in fields like natural language processing, data extraction, and data validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhp7XiXXh-CQ"
      },
      "source": [
        "Python includes a builtin module called `re` which provides regular expression matching operations (Click [here](https://docs.python.org/3/library/re.html) for the official module documentation). Once the module is imported into your code, you can use all of the available capabilities for performing pattern-based matching or searching using regular expressions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojyfJF7bymRl"
      },
      "source": [
        "\n",
        "\n",
        "##**Question - 1**\n",
        "\n",
        "##Write a Python script that uses regular expressions to extract all email addresses and URLs from a text. Ensure your script handles:\n",
        "\n",
        "##Multiple TLDs (e.g., .com, .org)\n",
        "##Edge cases like emails with numbers (e.g., john123@domain.com)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evyfHbBrveNw"
      },
      "outputs": [],
      "source": [
        "Input_text = \"For more details, contact us at support@myemail.com or visit https://example.org. Alternatively, you can email sales@company123.org.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wlcFDE341Idg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b0358fda-d07f-4adb-d209-3b4b071bdab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Email Addresses:\n",
            "support@myemail.com\n",
            "sales@company123.org\n",
            "\n",
            "Extracted URLs:\n",
            "https://example.org\n"
          ]
        }
      ],
      "source": [
        "#CODE HERE\n",
        "import re\n",
        "\n",
        "# Sample input text\n",
        "input_text = \"For more details, contact us at support@myemail.com or visit https://example.org. Alternatively, you can email sales@company123.org.\"\n",
        "\n",
        "# Regular expression for matching email addresses\n",
        "email_regex = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
        "\n",
        "# Regular expression for matching URLs\n",
        "url_regex = r'https?://[a-zA-Z0-9.-]+(?:\\.[a-zA-Z]{2,})+(?:/[^\\s]*)?'\n",
        "\n",
        "# Find all email addresses and URLs using regex\n",
        "emails = re.findall(email_regex, input_text)\n",
        "urls = re.findall(url_regex, input_text)\n",
        "\n",
        "# Print the results\n",
        "print(\"Extracted Email Addresses:\")\n",
        "for email in emails:\n",
        "    print(email)\n",
        "\n",
        "print(\"\\nExtracted URLs:\")\n",
        "for url in urls:\n",
        "    print(url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17YpjyzUo8oq"
      },
      "source": [
        "\n",
        "##**Question- 2**\n",
        "\n",
        "##Implement a Python program to find URLs in the given string using Regular expression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gRsGKmmskWJT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "86de85b5-daad-451b-c2be-50d59ad5eed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted URLs:\n",
            "https://w3resource.com\n",
            "http://github.com\n",
            "https://openai.com\n",
            "https://docs.python.org\n"
          ]
        }
      ],
      "source": [
        "text= '<p>Contents :</p><a href=\"https://w3resource.com\">Python Examples</a><a href=\"http://github.com\">Even More Examples</a><a href=\"https://openai.com\">OpenAI Homepage</a><a href=\"https://docs.python.org\">Python Documentation</a>'\n",
        "import re\n",
        "\n",
        "text = '<p>Contents :</p><a href=\"https://w3resource.com\">Python Examples</a><a href=\"http://github.com\">Even More Examples</a><a href=\"https://openai.com\">OpenAI Homepage</a><a href=\"https://docs.python.org\">Python Documentation</a>'\n",
        "url_regex = r'href=\"(https?://[a-zA-Z0-9.-]+(?:\\.[a-zA-Z]{2,})+(?:/[^\\s]*)?)\"'\n",
        "urls = re.findall(url_regex, text)\n",
        "print(\"Extracted URLs:\")\n",
        "for url in urls:\n",
        "    print(url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf1Pm9CHs1LM"
      },
      "source": [
        "## **Using regular expressions based pattern matching on real world text**\n",
        "\n",
        "For the purposes of demonstration, here's a dummy paragraph of text. A few observations here:\n",
        "* The text has multiple paragraphs with each paragraph having more than one sentence.\n",
        "* Some of the words are capitalized (first letter is in uppercase followed by lowercase letters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPLUtLxVtiTH"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Here is the First Paragraph and this is the First Sentence. here is the Second Sentence. now is the Third Sentence. this is the Fourth Sentence of the first paragaraph. this paragraph is ending now with a Fifth Sentence.\n",
        "Now, it is the Second Paragraph and its First Sentence. here is the Second Sentence. now is the Third Sentence. this is the Fourth Sentence of the second paragraph. this paragraph is ending now with a Fifth Sentence.\n",
        "Finally, this is the Third Paragraph and is the First Sentence of this paragraph. here is the Second Sentence. now is the Third Sentence. this is the Fourth Sentence of the third paragaraph. this paragraph is ending now with a Fifth Sentence.\n",
        "4th paragraph is not going to be detected by either of the regex patterns below.\n",
        "\"\"\"\n",
        "\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqmf8KSFtt2E"
      },
      "source": [
        "The following code block shows a regular expression that matches only those strings that:\n",
        "1. are at the start of a line and\n",
        "2. the string does not start with a number or a whitespace\n",
        "\n",
        "`re.findall()` finds all matches of the pattern in the text under consideration. The output is a list of strings that matched."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyYWQ5Tzttzt"
      },
      "source": [
        "Further, the regular expression defined below matches the words that are capitalized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxA3QOHHtqOg"
      },
      "outputs": [],
      "source": [
        "##code block - 3\n",
        "re_pattern2 = r'[A-Z][a-z]+'\n",
        "print(re.findall(re_pattern2, text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0VUlW3RunCd"
      },
      "source": [
        "\n",
        "Following is a text excerpt on \"Inaugural Address\" taken from the website of the [Joint Congressional Committee on Inaugural Ceremonies](https://www.inaugural.senate.gov/inaugural-address/):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRxR7M-NuFtR"
      },
      "outputs": [],
      "source": [
        "inau_text=\"\"\"The custom of delivering an address on Inauguration Day started with the very first Inauguration‚ÄîGeorge Washington‚Äôs‚Äîon April 30, 1789(04-30-1789). ex:-18.5. After taking his oath of office on the balcony of Federal Hall in New York City, Washington proceeded to the Senate chamber where he read a speech before members of Congress and other dignitaries. His second Inauguration took place in Philadelphia on March 4, 1793(03/04/1793), in the Senate chamber of Congress Hall. There, Washington gave the shortest Inaugural address on record‚Äîjust 135 words ‚Äîbefore repeating the oath of office.\n",
        "Every President since Washington has delivered an Inaugural address. While many of the early Presidents read their addresses before taking the oath, current custom dictates that the Chief Justice of the Supreme Court administer the oath first, followed by the President‚Äôs speech.\n",
        "William Henry Harrison delivered the longest Inaugural address, at 8,445 words, on March 4, 1841‚Äîa bitterly cold, wet day. He died one month later of pneumonia, believed to have been brought on by prolonged exposure to the elements on his Inauguration Day. John Adams‚Äô Inaugural address, which totaled 2,308 words, contained the longest sentence, at 737 words. After Washington‚Äôs second Inaugural address, the next shortest was Franklin D. Roosevelt‚Äôs fourth address on January 20, 1945(01-20-1945), at just 559.0 words. Roosevelt had chosen to have a simple Inauguration at the White House in light of the nation‚Äôs involvement in World War II.\n",
        "In 1921, Warren G. Harding became the first President to take his oath and deliver his Inaugural address through loud speakers. In 1925, Calvin Coolidge‚Äôs Inaugural address was the first to be broadcast nationally by radio. And in 1949, Harry S. Truman became the first President to deliver his Inaugural address over television airwaves.\n",
        "Most Presidents use their Inaugural address to present their vision of America and to set forth their goals for the nation. Some of the most eloquent and powerful speeches are still quoted today. In 1865, in the waning days of the Civil War, Abraham Lincoln stated, ‚ÄúWith malice toward none, with charity for all, with firmness in the right as God gives us to see the right, let us strive on to finish the work we are in, to bind up the nation‚Äôs wounds, to care for him who shall have borne the battle and for his widow and his orphan, to do all which may achieve and cherish a just and lasting peace among ourselves and with all nations.‚Äù In 1933, Franklin D. Roosevelt avowed, ‚Äúwe have nothing to fear but fear itself.‚Äù And in 1961, John F. Kennedy declared, ‚ÄúAnd so my fellow Americans: ask not what your country can do for you‚Äîask what you can do for your country.‚Äù\n",
        "Today, Presidents deliver their Inaugural address on the West Front of the Capitol, but this has not always been the case. Until Andrew Jackson‚Äôs first Inauguration in 1829, most Presidents spoke in either the House or Senate chambers. Jackson became the first President to take his oath of office and deliver his address on the East Front Portico of the U.S. Capitol in 1829. With few exceptions, the next 37.0 Inaugurations took place there, until 1981, when Ronald Reagan‚Äôs Swearing-In Ceremony and Inaugural address occurred on the West Front Terrace of the Capitol. The West Front has been used ever since. You should also need to extract the floating numbers such as -55.5, 20.8%, -3.0 using your regular expression\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qMOPAWe3wnj"
      },
      "source": [
        "Refer to  above code block -3 for the following questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Oap3GNEut1G"
      },
      "source": [
        "\n",
        "##**Questions-3.A**\n",
        "## Identify all the positive and neagtive numbers with type of both intergers,float  in the \"Inaugural Address\" excerpt and write a regular expression that finds all occurrences of such words in the text. Then, run the Python code snippet to automatically display the matched strings according to the pattern.*.\n",
        "\n",
        "NOTE: You can use the *re.findall()* method as demonstrated in the example before this exercise."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zJ3h197PoCea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BNqyUNbPurJm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "91d8ef87-48c6-42cc-f540-88f4b05d04ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['30', '178', '9', '04', '-30', '-178', '9', '-18.5', '4', '179', '3', '03', '04', '179', '3', '135', '8,445', '4', '184', '1', '2,308', '737', '20', '194', '5', '01', '-20', '-194', '5', '559.0', '192', '1', '192', '5', '194', '9', '186', '5', '193', '3', '196', '1', '182', '9', '182', '9', '37.0', '198', '1', '-55.5', '20.8%', '-3.0']\n"
          ]
        }
      ],
      "source": [
        "##Your code here\n",
        "import re\n",
        "\n",
        "# The text you provided\n",
        "inau_text = \"\"\"The custom of delivering an address on Inauguration Day started with the very first Inauguration‚ÄîGeorge Washington‚Äôs‚Äîon April 30, 1789(04-30-1789). ex:-18.5. After taking his oath of office on the balcony of Federal Hall in New York City, Washington proceeded to the Senate chamber where he read a speech before members of Congress and other dignitaries. His second Inauguration took place in Philadelphia on March 4, 1793(03/04/1793), in the Senate chamber of Congress Hall. There, Washington gave the shortest Inaugural address on record‚Äîjust 135 words ‚Äîbefore repeating the oath of office.\n",
        "Every President since Washington has delivered an Inaugural address. While many of the early Presidents read their addresses before taking the oath, current custom dictates that the Chief Justice of the Supreme Court administer the oath first, followed by the President‚Äôs speech.\n",
        "William Henry Harrison delivered the longest Inaugural address, at 8,445 words, on March 4, 1841‚Äîa bitterly cold, wet day. He died one month later of pneumonia, believed to have been brought on by prolonged exposure to the elements on his Inauguration Day. John Adams‚Äô Inaugural address, which totaled 2,308 words, contained the longest sentence, at 737 words. After Washington‚Äôs second Inaugural address, the next shortest was Franklin D. Roosevelt‚Äôs fourth address on January 20, 1945(01-20-1945), at just 559.0 words. Roosevelt had chosen to have a simple Inauguration at the White House in light of the nation‚Äôs involvement in World War II.\n",
        "In 1921, Warren G. Harding became the first President to take his oath and deliver his Inaugural address through loud speakers. In 1925, Calvin Coolidge‚Äôs Inaugural address was the first to be broadcast nationally by radio. And in 1949, Harry S. Truman became the first President to deliver his Inaugural address over television airwaves.\n",
        "Most Presidents use their Inaugural address to present their vision of America and to set forth their goals for the nation. Some of the most eloquent and powerful speeches are still quoted today. In 1865, in the waning days of the Civil War, Abraham Lincoln stated, ‚ÄúWith malice toward none, with charity for all, with firmness in the right as God gives us to see the right, let us strive on to finish the work we are in, to bind up the nation‚Äôs wounds, to care for him who shall have borne the battle and for his widow and his orphan, to do all which may achieve and cherish a just and lasting peace among ourselves and with all nations.‚Äù In 1933, Franklin D. Roosevelt avowed, ‚Äúwe have nothing to fear but fear itself.‚Äù And in 1961, John F. Kennedy declared, ‚ÄúAnd so my fellow Americans: ask not what your country can do for you‚Äîask what you can do for your country.‚Äù\n",
        "Today, Presidents deliver their Inaugural address on the West Front of the Capitol, but this has not always been the case. Until Andrew Jackson‚Äôs first Inauguration in 1829, most Presidents spoke in either the House or Senate chambers. Jackson became the first President to take his oath of office and deliver his address on the East Front Portico of the U.S. Capitol in 1829. With few exceptions, the next 37.0 Inaugurations took place there, until 1981, when Ronald Reagan‚Äôs Swearing-In Ceremony and Inaugural address occurred on the West Front Terrace of the Capitol. The West Front has been used ever since. You should also need to extract the floating numbers such as -55.5, 20.8%, -3.0 using your regular expression\"\"\"\n",
        "\n",
        "# Updated regular expression to handle numbers with commas and decimals, also including negative numbers and percentages\n",
        "pattern = r'(-?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?%?)'\n",
        "\n",
        "# Find all matches using re.findall\n",
        "matches = re.findall(pattern, inau_text)\n",
        "\n",
        "# Output all the matches\n",
        "print(matches)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWQdvlG0dPKy"
      },
      "source": [
        "##Your explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mkbLF4nu7la"
      },
      "source": [
        "##**Question-3.B**\n",
        "##*Identify all the dates of all forms - text form(April 20, 1945) and digit form(xx-xx-xxxx, xx/xx/xxxx) in the \"Inaugural Address\" excerpt and write a regular expression that finds all occurrences of the dates in the text. Then, run the Python code snippet to automatically display a list of all such dates identified.*\n",
        "\n",
        "NOTE: You can use the *re.findall()* method as demonstrated in the example before this exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2pxl72VhvEcG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4111c1e3-0507-4fd1-d086-8b2956636959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['April 30, 1789', '04-30-1789', 'March 4, 1793', '03/04/1793', 'March 4, 1841', 'January 20, 1945', '01-20-1945']\n"
          ]
        }
      ],
      "source": [
        "##Your code here\n",
        "import re\n",
        "\n",
        "inau_text = \"\"\"The custom of delivering an address on Inauguration Day started with the very first Inauguration‚ÄîGeorge Washington‚Äôs‚Äîon April 30, 1789(04-30-1789). ex:-18.5. After taking his oath of office on the balcony of Federal Hall in New York City, Washington proceeded to the Senate chamber where he read a speech before members of Congress and other dignitaries. His second Inauguration took place in Philadelphia on March 4, 1793(03/04/1793), in the Senate chamber of Congress Hall. There, Washington gave the shortest Inaugural address on record‚Äîjust 135 words ‚Äîbefore repeating the oath of office.\n",
        "Every President since Washington has delivered an Inaugural address. While many of the early Presidents read their addresses before taking the oath, current custom dictates that the Chief Justice of the Supreme Court administer the oath first, followed by the President‚Äôs speech.\n",
        "William Henry Harrison delivered the longest Inaugural address, at 8,445 words, on March 4, 1841‚Äîa bitterly cold, wet day. He died one month later of pneumonia, believed to have been brought on by prolonged exposure to the elements on his Inauguration Day. John Adams‚Äô Inaugural address, which totaled 2,308 words, contained the longest sentence, at 737 words. After Washington‚Äôs second Inaugural address, the next shortest was Franklin D. Roosevelt‚Äôs fourth address on January 20, 1945(01-20-1945), at just 559.0 words. Roosevelt had chosen to have a simple Inauguration at the White House in light of the nation‚Äôs involvement in World War II.\n",
        "In 1921, Warren G. Harding became the first President to take his oath and deliver his Inaugural address through loud speakers. In 1925, Calvin Coolidge‚Äôs Inaugural address was the first to be broadcast nationally by radio. And in 1949, Harry S. Truman became the first President to deliver his Inaugural address over television airwaves.\n",
        "Most Presidents use their Inaugural address to present their vision of America and to set forth their goals for the nation. Some of the most eloquent and powerful speeches are still quoted today. In 1865, in the waning days of the Civil War, Abraham Lincoln stated, ‚ÄúWith malice toward none, with charity for all, with firmness in the right as God gives us to see the right, let us strive on to finish the work we are in, to bind up the nation‚Äôs wounds, to care for him who shall have borne the battle and for his widow and his orphan, to do all which may achieve and cherish a just and lasting peace among ourselves and with all nations.‚Äù In 1933, Franklin D. Roosevelt avowed, ‚Äúwe have nothing to fear but fear itself.‚Äù And in 1961, John F. Kennedy declared, ‚ÄúAnd so my fellow Americans: ask not what your country can do for you‚Äîask what you can do for your country.‚Äù\n",
        "Today, Presidents deliver their Inaugural address on the West Front of the Capitol, but this has not always been the case. Until Andrew Jackson‚Äôs first Inauguration in 1829, most Presidents spoke in either the House or Senate chambers. Jackson became the first President to take his oath of office and deliver his address on the East Front Portico of the U.S. Capitol in 1829. With few exceptions, the next 37.0 Inaugurations took place there, until 1981, when Ronald Reagan‚Äôs Swearing-In Ceremony and Inaugural address occurred on the West Front Terrace of the Capitol. The West Front has been used ever since.\"\"\"\n",
        "\n",
        "# Define regex pattern for dates\n",
        "re_pattern = r'([A-Za-z]+ \\d{1,2}, \\d{4}|[0-3]?\\d[-/][0-3]?\\d[-/]\\d{4})'\n",
        "\n",
        "# Find all matches in the text\n",
        "dates = re.findall(re_pattern, inau_text)\n",
        "\n",
        "# Display the list of matched dates\n",
        "print(dates)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdUT4vfidQ_L"
      },
      "source": [
        "##Your explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZSO1IrN06xI"
      },
      "source": [
        "#**Task 3: Lemmatization/Stemming(25%)**\n",
        "\n",
        "\n",
        "#**Question -1:**\n",
        "##How does the morphology of a language (e.g., agglutinative vs. fusional) impact the suitability of stemming vs. lemmatization?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80ycUYp41Iy_"
      },
      "source": [
        "##Your answer here\n",
        "The morphology of the languages has a significant contribution towards choosing between lemmatization and stemming for text processing. In agglutinative languages like Turkish and Finnish, where affixes are added on top of root words in order to express such categories as tense and case, stemming can be useful because it only strips away affix. But since there can be several affix variations, stemming may not be accurate. Lemmatization, however, looks at the whole shape of the word and can be more accurate in such languages, because it can correctly determine the root shape.\n",
        "\n",
        "Fusional languages like Spanish and Russian pack several different pieces of grammar into a single affix. Owing to such complexity, stemming becomes ineffective because it may not be able to disjoin root and affix. Lemmatization, however, works best for such languages because it looks for the whole shape of the word and its context, and reduces more exactly to the root."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMMf51DdsaK5"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        " ## **Question - 2 :**\n",
        "\n",
        "\n",
        "## Create a Python function that takes a sentence as input, performs lemmatization using **Stanza**, and removes stopwords from the lemmatized sentence.Return the cleaned and lemmatized sentence.\n",
        "\n",
        "Reference: https://github.com/stanfordnlp/stanza\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "udt8qI_viOXf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "aba42ab7-5ed7-49df-feca-e1bbcf5b4770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.10.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting emoji (from stanza)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from stanza) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.11/dist-packages (from stanza) (4.25.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from stanza) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from stanza) (3.4.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from stanza) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stanza) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3.0->stanza) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n",
            "Downloading stanza-1.10.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m839.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, emoji, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stanza\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed emoji-2.14.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stanza-1.10.1\n"
          ]
        }
      ],
      "source": [
        "#CODE HERE\n",
        "!pip install stanza\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install stanza if not installed\n",
        "import stanza\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download necessary resources\n",
        "nltk.download('stopwords')\n",
        "stanza.download('en')\n",
        "\n",
        "# Load the Stanza pipeline\n",
        "nlp = stanza.Pipeline(lang='en', processors='tokenize,lemma')\n",
        "\n",
        "def clean_lemmatize_sentence(sentence):\n",
        "    \"\"\"Lemmatizes the input sentence using Stanza and removes stopwords.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    lemmatized_words = [\n",
        "        word.lemma for sent in doc.sentences for word in sent.words if word.lemma.lower() not in stop_words\n",
        "    ]\n",
        "\n",
        "    return \" \".join(lemmatized_words)\n",
        "\n",
        "# Example usage\n",
        "sentence = \"The cats are running quickly in the beautiful garden.\"\n",
        "cleaned_sentence = clean_lemmatize_sentence(sentence)\n",
        "print(cleaned_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562,
          "referenced_widgets": [
            "ef28c79c9638448a85a6f1a449696556",
            "2ec63e9150594d179291321dd4481872",
            "f4725846a85b4a1f85e3252039319fb4",
            "fea0f5a194774d04823e10d0abe01562",
            "a2c0c92658ba46dfbb69b7b7ba24812d",
            "2d2aabd5f51644ddb43d6c899b538985",
            "de805a3debbf47a399227f889c4b7ed3",
            "dc7042bd54b7468bba1999077095b4bb",
            "5546fbaeb95444bc8163f03cc13dc8b0",
            "9ddd0ae7c65d41e39813401a0571e2e8",
            "86c88b7e9c144afdb672d888ca8f5991",
            "c9a7bd52bd704079abd96c4f817ef401",
            "e5b3ec012b9442ec96676e58729480bc",
            "05610c9876f145da8b28072113b2f361",
            "e98856b36768432fa82d6c39f51ca4f3",
            "bd50f50313e74455a64ce52cf4cb9afe",
            "8e5a03726c344613aa4086026d3807a5",
            "4792e2353fef4520a614397a89e763b9",
            "5b7e275465ec425e81a67724a1d79176",
            "fcb1a3d2a6604b738757ff256ed28182",
            "b5b3eb7bcf3d4828a71887a584a11b49",
            "09c978ca1a7c4fd7961fce9fa50c7ca0",
            "f246880665a1465ea73fd68a896dca66",
            "41279b834e3b4a9da7eee249844911d1",
            "b7f1bde726f446b585fbf018aa128b77",
            "87578489c07a4c458855454647084094",
            "e6b5b59dc84b47328a3eec95d2a2fdf9",
            "4283d5a00c564680a6c3853984125136",
            "111e1c8b41c44d6288cdf02b25ada365",
            "ad8d5d49d93148d48b5c504398a8f916",
            "91af9b57b8a94bd7ad5e7d0baba18e39",
            "1934aee0bcdd4e65b692d4339579aeb2",
            "6041c8f7869440ea902ac05b5c97a3fa"
          ]
        },
        "id": "u3oyTNQ9zpM-",
        "outputId": "7b8f3fea-47e7-471e-dc86-bf47e9f4bfd7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef28c79c9638448a85a6f1a449696556"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "INFO:stanza:Downloading default packages for language: en (English) ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.10.0/models/default.zip:   0%|          | ‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9a7bd52bd704079abd96c4f817ef401"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/en/default.zip\n",
            "INFO:stanza:Finished downloading models and saved to /root/stanza_resources\n",
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f246880665a1465ea73fd68a896dca66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "WARNING:stanza:Language en package default expects mwt, which has been added\n",
            "INFO:stanza:Loading these models for language: en (English):\n",
            "=================================\n",
            "| Processor | Package           |\n",
            "---------------------------------\n",
            "| tokenize  | combined          |\n",
            "| mwt       | combined          |\n",
            "| lemma     | combined_nocharlm |\n",
            "=================================\n",
            "\n",
            "INFO:stanza:Using device: cpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: mwt\n",
            "INFO:stanza:Loading: lemma\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat run quickly beautiful garden .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri0OIiWfBN8R"
      },
      "source": [
        "##Your answer here\n",
        "\n",
        "> Add blockquote\n",
        "Lemmatization and stop removal are two of the principal natural process techniques for text preprocessing for analysis. Lemmatization normalizes the words into their root forms or their forms from the dictionary for representation. Verbs like \"running\" are normalized into \"run,\" and plurals like \"cats\" into \"cat.\" The process aids text improvement with normalizing varying forms of a word. The stop removal, however, filters frequent occurrence and semantics-negligible terms such as \"the,\" \"are,\" and \"in.\" The terms don't matter for semantics for the majority of the NLP processes and therefore are not considered for enhanced performance. If the two processes are performed, a sentence is normalized into a more compact and significant representation with major content terms. The output has key semantics and ignores extraneous contents, and the text becomes ready for other processes such as classification and searching for data.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7o1E0wTupIA"
      },
      "source": [
        "##**Question - 3**\n",
        "\n",
        "(Refer to the byte pair encoding concept which is explained in activity-3 at the Tutorial of Subword Tokenization using HuggingFace after the Question-6 in activity-3)\n",
        "\n",
        "\n",
        "Consider the following two sentences:\n",
        "\n",
        "**S1:** \"The artist is creating a better version of his masterpiece by refining the details.\"\n",
        "\n",
        "**S2:**\"She is bettering her artistic skills by creating new versions of her paintings.\"\n",
        "\n",
        "**Create a Python function that encodes two sentences using the custom BPE tokenizer and identifies common subword tokens (tokens that appear in both encodings). Return a list of these common subword tokens. Is/Are there any interesting observations when you compare the tokens between the two encodings? What do you think is causing what you observe as part of your comparison?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3RY65-RPvURG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "83f8988d-3d17-4c1d-db69-43d6dc702d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common subword tokens: ['of', '.', 'by', 'creating', 'is']\n"
          ]
        }
      ],
      "source": [
        "#code here\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "def train_bpe_tokenizer(sentences):\n",
        "    tokenizer = Tokenizer(BPE())\n",
        "    tokenizer.pre_tokenizer = Whitespace()\n",
        "    trainer = BpeTrainer(special_tokens=[\"<unk>\", \"<s>\", \"</s>\"])\n",
        "    tokenizer.train_from_iterator(sentences, trainer)\n",
        "    return tokenizer\n",
        "\n",
        "def find_common_bpe_tokens(sentence1, sentence2):\n",
        "    sentences = [sentence1, sentence2]\n",
        "    tokenizer = train_bpe_tokenizer(sentences)\n",
        "\n",
        "    encoding1 = tokenizer.encode(sentence1).tokens\n",
        "    encoding2 = tokenizer.encode(sentence2).tokens\n",
        "\n",
        "    common_tokens = list(set(encoding1) & set(encoding2))\n",
        "    return common_tokens\n",
        "\n",
        "s1 = \"The artist is creating a better version of his masterpiece by refining the details.\"\n",
        "s2 = \"She is bettering her artistic skills by creating new versions of her paintings.\"\n",
        "\n",
        "common_subwords = find_common_bpe_tokens(s1, s2)\n",
        "print(\"Common subword tokens:\", common_subwords)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEKqJAYbvUG3"
      },
      "source": [
        "# **Task - 4 : Minimum Edit distance (25%)**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##Minimum edit Distance\n",
        "Minimum Edit Distance (also known as Levenshtein Distance) is a measure of similarity between two strings by calculating the minimum number of single-character edits (insertions, deletions, substitutions) required to transform one string into the other. It has applications in various fields, including natural language processing, spell checking, DNA sequence alignment, and more.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNZzSXu2xoAI"
      },
      "source": [
        "# Character Based Text Similarity\n",
        "\"As an example, this technology is used by information retrieval systems, search engines, automatic indexing systems, text summarizers, categorization systems, plagiarism checkers, speech recognition, rating systems, DNA analysis, and profiling algorithms (IR/AI programs to automatically link data between people and what they do).\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHA_ccV_xmCB"
      },
      "outputs": [],
      "source": [
        "##code block -4\n",
        "# A Naive recursive Python program to find minimum number\n",
        "# operations to convert str1 to str2\n",
        "\n",
        "\n",
        "def editDistance(str1, str2, m, n):\n",
        "\n",
        "    # If first string is empty, the only option is to\n",
        "    # insert all characters of second string into first\n",
        "    if m == 0:\n",
        "        return n\n",
        "\n",
        "    # If second string is empty, the only option is to\n",
        "    # remove all characters of first string\n",
        "    if n == 0:\n",
        "        return m\n",
        "\n",
        "    # If last characters of two strings are same, nothing\n",
        "    # much to do. Ignore last characters and get count for\n",
        "    # remaining strings.\n",
        "    if str1[m-1] == str2[n-1]:\n",
        "        return editDistance(str1, str2, m-1, n-1)\n",
        "\n",
        "    # If last characters are not same, consider all three\n",
        "    # operations on last character of first string, recursively\n",
        "    # compute minimum cost for all three operations and take\n",
        "    # minimum of three values.\n",
        "    return 1 + min(editDistance(str1, str2, m, n-1),    # Insert\n",
        "                   editDistance(str1, str2, m-1, n),    # Remove\n",
        "                   editDistance(str1, str2, m-1, n-1)    # Replace\n",
        "                   )\n",
        "\n",
        "\n",
        "# Driver code\n",
        "str1 = \"sunday\"\n",
        "str2 = \"saturday\"\n",
        "print (editDistance(str1, str2, len(str1), len(str2)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSfpOff4Ngbx"
      },
      "source": [
        "Refer above code block -4  for the following question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUJ1n35-dgON"
      },
      "source": [
        "##Question-1\n",
        "##Assuming case sensitivity where changing a letter's case has a cost of 1, calculate the minimum cost to transform \"Educate\" into \"Education\" with the following operation costs: insertions = 3, deletions = 1, substitutions = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bt4ZjDL2c3LB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "008b111c-8370-4834-9cae-c19003f18e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum cost: 8\n"
          ]
        }
      ],
      "source": [
        "def min_edit_distance(str1, str2):\n",
        "    m, n = len(str1), len(str2)\n",
        "    INSERT_COST = 3\n",
        "    DEL_COST = 1\n",
        "    SUB_COST = 2\n",
        "    CHANGE_COST = 1\n",
        "    dp = [[0 for _ in range(n + 1)] for _ in range(m + 1)]\n",
        "\n",
        "    for i in range(m + 1):\n",
        "        for j in range(n + 1):\n",
        "            if i == 0:\n",
        "                dp[i][j] = j * INSERT_COST\n",
        "            elif j == 0:\n",
        "                dp[i][j] = i * DEL_COST\n",
        "            elif str1[i - 1] == str2[j - 1]:\n",
        "                dp[i][j] = dp[i - 1][j - 1]\n",
        "            elif str1[i - 1].lower() == str2[j - 1].lower():\n",
        "                dp[i][j] = dp[i - 1][j - 1] + CHANGE_COST\n",
        "            else:\n",
        "                dp[i][j] = min(\n",
        "                    dp[i][j - 1] + INSERT_COST,\n",
        "                    dp[i - 1][j] + DEL_COST,\n",
        "                    dp[i - 1][j - 1] + SUB_COST\n",
        "                )\n",
        "\n",
        "    return dp[m][n]\n",
        "str1 = \"Educate\"\n",
        "str2 = \"Education\"\n",
        "print(\"Minimum cost:\", min_edit_distance(str1, str2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fdCkNgZdL7_"
      },
      "source": [
        "##Your explanation\n",
        "To determine the minimum amount of money required for transforming \"Educate\" into \"Education\" with consideration of case and with insertions charged 3, deletions charged 1, and substitutions charged 2, we use the edit distance algorithm with the use of dynamic programming. The algorithm creates a table where each cell has the minimum amount of money for transforming a string of characters of \"Educate\" into a string of characters of \"Education.\"\n",
        "\n",
        "The transformation insert a letter into the beginning of a string, delete a letter, and replace a letter with another. If two letters are equal, there's nothing charged, and if not, the algorithm has the least costly operation. With upper and lower case considered, a letter altering its upper and lower case, being equal, being a replace with a charge of 1. The algorithm repeatedly finds the least charge for transforming \"Educate\" into \"Education\" with the least sequence of insertions, deletions, and replaces being 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFiLMn7rIHUd"
      },
      "source": [
        "##Tutorial -2\n",
        "# Levenshtein Distance for Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FypLc-dkO96G"
      },
      "outputs": [],
      "source": [
        "#code block - 5\n",
        "# Simple Minimum Edit Distance\n",
        "def levenshtein_distance(str1, str2):\n",
        "    # Initialize a matrix to store edit distances\n",
        "    m, n = len(str1), len(str2)\n",
        "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "\n",
        "    # Initialize the first row and column\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    # Fill in the matrix using dynamic programming\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            cost = 0 if str1[i - 1] == str2[j - 1] else 2  # Substitution cost is 2\n",
        "            dp[i][j] = min(\n",
        "                dp[i - 1][j] + 1,  # Deletion\n",
        "                dp[i][j - 1] + 1,  # Insertion\n",
        "                dp[i - 1][j - 1] + cost,  # Substitution\n",
        "            )\n",
        "\n",
        "    # The final value in the matrix represents the Levenshtein distance\n",
        "    return dp[m][n]\n",
        "\n",
        "# Example usage\n",
        "str1 = \"This is a cat\"\n",
        "str2 = \"That is a dog\"\n",
        "distance = levenshtein_distance(str1, str2)\n",
        "print(f\"The Levenshtein distance between '{str1}' and '{str2}' with substitution cost 2 is {distance}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-xrzKVC5iSe"
      },
      "source": [
        "Refer to above code block -5 from tutorial - 2 for the following question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EapfLAq5iCLo"
      },
      "source": [
        "##Question:2\n",
        "##Assign different costs to insertions, deletions, and substitutions to reflect varying penalties for different types of edits. Calculate the Levenshtein distance with these weighted costs.\n",
        "\n",
        "String1 = (\"Natural language processing\")\n",
        "\n",
        "String2 = (\"Computer science department\")\n",
        "\n",
        "Provide your explanation in the tex block below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kcDvlYTD4YvR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3c7a455a-43a6-4678-fa6f-0705b67edd0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weighted Levenshtein distance between 'Natural language processing' and 'Computer science department' is 76\n"
          ]
        }
      ],
      "source": [
        "##ENTER YOUR CODE HERE\n",
        "def weighted_levenshtein_distance(str1, str2, insert_cost=3, del_cost=2, sub_cost=4):\n",
        "    m, n = len(str1), len(str2)\n",
        "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i * del_cost\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j * insert_cost\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            if str1[i - 1] == str2[j - 1]:\n",
        "                cost = 0\n",
        "            else:\n",
        "                cost = sub_cost\n",
        "\n",
        "            dp[i][j] = min(\n",
        "                dp[i - 1][j] + del_cost,\n",
        "                dp[i][j - 1] + insert_cost,\n",
        "                dp[i - 1][j - 1] + cost\n",
        "            )\n",
        "\n",
        "    return dp[m][n]\n",
        "string1 = \"Natural language processing\"\n",
        "string2 = \"Computer science department\"\n",
        "distance = weighted_levenshtein_distance(string1, string2)\n",
        "print(f\"The weighted Levenshtein distance between '{string1}' and '{string2}' is {distance}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "texg77AFdG6A"
      },
      "source": [
        "##Your explanation\n",
        "The weighted Levenshtein algorithm determines the minimum conversion cost of two strings with different insertions, deletions, and substitutions being charged different penalty values. The insertions are charged 3, deletions 2, and substitutions 4. The algorithm constructs a table where every cell represents the overall conversion cost of substr of \"Natural language processing\" into substr of \"Computer science department\" up till this point. It determines the possible action for every step and chooses the minimum action with maximum efficacy. Since the two strings also differ with regard to their characters and their count, the result of 76 indicates a huge number of operations needed to be conducted for their matching."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg7XS-bAztur"
      },
      "source": [
        "# Question -3\n",
        "\n",
        "##Modify the minimum edit distance algorithm to account for different penalties:\n",
        "\n",
        "Insertion = 1\n",
        "\n",
        "Deletion = 2\n",
        "\n",
        "Substitution = 3\n",
        "\n",
        "Apply it to the following sentences:\n",
        "\n",
        "**Senetence 1 = \"Data Science is evolving fast.**\"\n",
        "\n",
        "**Senetence 2 = \"Artificial Intelligence is transforming industries.**\"\n",
        "\n",
        "\n",
        "Explain how different weights reflect real-world penalties in tasks like document comparison or DNA sequence matching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xjRSiKhj0avx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "432726aa-3366-4aba-a0c3-c44ebb532f92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted Edit Distance: 51\n"
          ]
        }
      ],
      "source": [
        "# code here\n",
        "def weighted_edit_distance(str1, str2):\n",
        "    m, n = len(str1), len(str2)\n",
        "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "    INSERT_COST = 1\n",
        "    DEL_COST = 2\n",
        "    SUB_COST = 3\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i * DEL_COST\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j * INSERT_COST\n",
        " # Compute the edit distance dynamically\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            if str1[i - 1] == str2[j - 1]:\n",
        "                cost = 0\n",
        "            else:\n",
        "                cost = SUB_COST\n",
        "\n",
        "            dp[i][j] = min(\n",
        "                dp[i - 1][j] + DEL_COST,\n",
        "                dp[i][j - 1] + INSERT_COST,\n",
        "                dp[i - 1][j - 1] + cost\n",
        "            )\n",
        "\n",
        "    return dp[m][n]\n",
        "sentence1 = \"Data Science is evolving fast.\"\n",
        "sentence2 = \"Artificial Intelligence is transforming industries.\"\n",
        "distance = weighted_edit_distance(sentence1, sentence2)\n",
        "print(\"Weighted Edit Distance:\", distance)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The weighted edit distance algorithm supports insertions, deletions, and substitutions with different penalty values, and therefore more useful for real examples. The varying penalty values in text similarities calculation imply the amount of changing necessary for two pieces of text for them to be similar. Low insertions can imply low paraphrasing, for example, in plagiarism, and greater substitutions can imply more changing of content. Similarly, for alignments of DNA sequence, substitutions can imply mutations, deletions can imply gene loss, and insertions can imply evolutionary adaptations. With varying weight, we can symbolize real significance of every edit."
      ],
      "metadata": {
        "id": "FVGGmxY-0-9H"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zLdz7KC0YbC"
      },
      "source": [
        "##Question-4\n",
        "##Explain how Minimum Edit Distance (MED) is applied in NLP tasks like spell checking, speech recognition, text summarization, and machine translation. How does its effectiveness differ across these tasks?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfyAF_SacJZd"
      },
      "source": [
        "##Your Explanation\n",
        "Minimum Edit Distance (MED) has widespread use in NLP to compute the text sequence similarity as the minimum number of insertions, deletions, and substitutions required to transform one sequence into another. MED in spell check aids in detecting and correcting spelling error by comparing words with a dictionary and providing the most suitable match. In speech recognition, it calculates transcription accuracy by comparing predicted-reference text differences, although other models must be employed where there is phonetic difference. In text summarization, MED is used to calculate similarity between generated and reference summaries, although due to the paraphrasing nature of summarization, it is usually blended with other measures like ROUGE. With machine translation, MED can be used for comparing translations to reference text but does not note differences in meaning and is thus outperformed by BLEU and METEOR. Even though effective under strict text matching, the performance of MED varies with semantic understanding tasks."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ef28c79c9638448a85a6f1a449696556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ec63e9150594d179291321dd4481872",
              "IPY_MODEL_f4725846a85b4a1f85e3252039319fb4",
              "IPY_MODEL_fea0f5a194774d04823e10d0abe01562"
            ],
            "layout": "IPY_MODEL_a2c0c92658ba46dfbb69b7b7ba24812d"
          }
        },
        "2ec63e9150594d179291321dd4481872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d2aabd5f51644ddb43d6c899b538985",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_de805a3debbf47a399227f889c4b7ed3",
            "value": "Downloading‚Äáhttps://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:‚Äá"
          }
        },
        "f4725846a85b4a1f85e3252039319fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc7042bd54b7468bba1999077095b4bb",
            "max": 52452,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5546fbaeb95444bc8163f03cc13dc8b0",
            "value": 52452
          }
        },
        "fea0f5a194774d04823e10d0abe01562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ddd0ae7c65d41e39813401a0571e2e8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_86c88b7e9c144afdb672d888ca8f5991",
            "value": "‚Äá424k/?‚Äá[00:00&lt;00:00,‚Äá28.6MB/s]"
          }
        },
        "a2c0c92658ba46dfbb69b7b7ba24812d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d2aabd5f51644ddb43d6c899b538985": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de805a3debbf47a399227f889c4b7ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc7042bd54b7468bba1999077095b4bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5546fbaeb95444bc8163f03cc13dc8b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ddd0ae7c65d41e39813401a0571e2e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c88b7e9c144afdb672d888ca8f5991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9a7bd52bd704079abd96c4f817ef401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5b3ec012b9442ec96676e58729480bc",
              "IPY_MODEL_05610c9876f145da8b28072113b2f361",
              "IPY_MODEL_e98856b36768432fa82d6c39f51ca4f3"
            ],
            "layout": "IPY_MODEL_bd50f50313e74455a64ce52cf4cb9afe"
          }
        },
        "e5b3ec012b9442ec96676e58729480bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e5a03726c344613aa4086026d3807a5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4792e2353fef4520a614397a89e763b9",
            "value": "Downloading‚Äáhttps://huggingface.co/stanfordnlp/stanza-en/resolve/v1.10.0/models/default.zip:‚Äá100%"
          }
        },
        "05610c9876f145da8b28072113b2f361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b7e275465ec425e81a67724a1d79176",
            "max": 526251983,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcb1a3d2a6604b738757ff256ed28182",
            "value": 526251983
          }
        },
        "e98856b36768432fa82d6c39f51ca4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5b3eb7bcf3d4828a71887a584a11b49",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_09c978ca1a7c4fd7961fce9fa50c7ca0",
            "value": "‚Äá526M/526M‚Äá[00:03&lt;00:00,‚Äá236MB/s]"
          }
        },
        "bd50f50313e74455a64ce52cf4cb9afe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e5a03726c344613aa4086026d3807a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4792e2353fef4520a614397a89e763b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b7e275465ec425e81a67724a1d79176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcb1a3d2a6604b738757ff256ed28182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5b3eb7bcf3d4828a71887a584a11b49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c978ca1a7c4fd7961fce9fa50c7ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f246880665a1465ea73fd68a896dca66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41279b834e3b4a9da7eee249844911d1",
              "IPY_MODEL_b7f1bde726f446b585fbf018aa128b77",
              "IPY_MODEL_87578489c07a4c458855454647084094"
            ],
            "layout": "IPY_MODEL_e6b5b59dc84b47328a3eec95d2a2fdf9"
          }
        },
        "41279b834e3b4a9da7eee249844911d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4283d5a00c564680a6c3853984125136",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_111e1c8b41c44d6288cdf02b25ada365",
            "value": "Downloading‚Äáhttps://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:‚Äá"
          }
        },
        "b7f1bde726f446b585fbf018aa128b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad8d5d49d93148d48b5c504398a8f916",
            "max": 52452,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91af9b57b8a94bd7ad5e7d0baba18e39",
            "value": 52452
          }
        },
        "87578489c07a4c458855454647084094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1934aee0bcdd4e65b692d4339579aeb2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6041c8f7869440ea902ac05b5c97a3fa",
            "value": "‚Äá424k/?‚Äá[00:00&lt;00:00,‚Äá16.9MB/s]"
          }
        },
        "e6b5b59dc84b47328a3eec95d2a2fdf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4283d5a00c564680a6c3853984125136": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "111e1c8b41c44d6288cdf02b25ada365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad8d5d49d93148d48b5c504398a8f916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91af9b57b8a94bd7ad5e7d0baba18e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1934aee0bcdd4e65b692d4339579aeb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6041c8f7869440ea902ac05b5c97a3fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}